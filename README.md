# Eyetracker Remote Mouse Controller fÃ¼r Notebooks

ğŸ¯ **Status: FunktionsfÃ¤higer Prototyp verfÃ¼gbar!** 

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8+-green.svg)](https://opencv.org/)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10+-red.svg)](https://mediapipe.dev/)

## Schnellstart

### Sofort testen (Basis-Prototyp):
```bash
# Repository klonen
git clone <REPO_URL>
cd EyetrackerRemoteMouseController

# Virtual Environment aktivieren und Dependencies installieren
.venv\Scripts\activate
pip install -r requirements.txt

# Basis-Prototyp starten (Kopfsteuerung)
python main.py
```

**Steuerung:** Bewegen Sie Ihren Kopf um die Maus zu steuern. DrÃ¼cken Sie 'q' zum Beenden, 'c' zum Zentrieren.

---

## 1. ProjektÃ¼bersicht

Dieses Projekt zielt darauf ab, einen innovativen und ressourcenschonenden Eyetracker-RemoteMouse-Controller fÃ¼r Notebooks zu entwickeln. Das System ermÃ¶glicht die Steuerung des Mauszeigers und die AusfÃ¼hrung von Mausklicks ausschlieÃŸlich durch Augen- und Kopfbewegungen, unter Verwendung der integrierten Webcam des Notebooks. Das ultimative Ziel ist es, die AbhÃ¤ngigkeit von physischen MÃ¤usen oder Touchpads zu reduzieren oder ganz zu eliminieren und so eine intuitive, ermÃ¼dungsfreie Interaktion zu ermÃ¶glichen.

## 2. Kernfunktionen und Anforderungen

### 2.1 Start und Beenden des Programms

*   **Programmstart:** Das Hauptprogramm wird durch einen Doppelklick mit der rechten Maustaste (oder Touchpad-Taste) ausgelÃ¶st, unabhÃ¤ngig von der aktuellen Position des Mauszeigers.
*   **Automatisches Beenden:** Wenn der Mauszeiger eine einstellbare Zeit (Standard: 5-10 Sekunden) in seiner Ruheposition verweilt, ohne dass eine erkennbare Augenbewegung zur Mauszeigerverschiebung erfolgt, beendet sich das Programm automatisch. Es muss dann wie oben beschrieben neu gestartet werden.

### 2.2 Mauszeiger-Status und Visualisierung

*   **Ruheposition:** Nach dem Start des Programms oder nach jeder durchgefÃ¼hrten Aktion befindet sich der Mauszeiger in seiner vertikal und horizontal zentrierten Ruheposition in der Bildschirmmitte.
*   **Visuelle RÃ¼ckmeldung:** In der Ruheposition ist der Mauszeiger deutlich sichtbar grÃ¶ÃŸer, um den aktiven Status des Eyetrackers zu signalisieren.
*   **RÃ¼ckkehr in die Ruheposition:**
    *   Nach jeder erfolgreich ausgefÃ¼hrten Aktion (Mauszeiger verschoben und Trigger erkannt) kehrt der Mauszeiger sofort in seine Ruheposition zurÃ¼ck.
    *   Wenn lÃ¤nger als eine einstellbare Zeit (Standard: 1 Sekunde) kein Blick- oder Kopfbewegungsbefehl erfolgt, kehrt der Mauszeiger ebenfalls in seine Ruheposition zurÃ¼ck.

### 2.3 Mauszeiger-Steuerung durch Augenbewegung

*   **Bewegung aus der Ruheposition:** Wenn der Benutzer den zentrierten Mauszeiger mit den Augen fixiert und eine **annÃ¤hernd lineare Augenbewegung** von der Bildschirmmitte weg ausfÃ¼hrt, folgt der Mauszeiger dieser Bewegung. Kreiselnde, zick-zack- oder wellenfÃ¶rmige Augenbewegungen aus der Ruheposition heraus werden ignoriert, um unbeabsichtigte Bewegungen zu vermeiden.
*   **Fixierung und Halten:** Der Mauszeiger bleibt an der Stelle stehen, an die er verschoben wurde und wo der Benutzer ihn **lÃ¤nger als eine Sekunde ununterbrochen** (ohne Blinzeln) fixiert hat.
*   **Feinjustierung:** Nach der Erkennung einer annÃ¤hernd linearen Bewegung und dem Erreichen der Zielregion ist fÃ¼r eine kurze, einstellbare Zeitspanne (Standard: 0.5 Sekunden) eine Feinjustierung des Mauszeigers durch subtile Augenbewegungen mÃ¶glich, bevor die Position endgÃ¼ltig fixiert wird.

### 2.4 Aktionen und Trigger

*   **AktionsausfÃ¼hrung:** Sobald der Mauszeiger an einer gewÃ¼nschten Position fixiert wurde, kann durch einen spezifischen Trigger eine Aktion ausgefÃ¼hrt werden.
*   **Beispiele fÃ¼r Trigger (erweiterbar):**
    *   **Kopfnicken:** Ein kurzes, klares Nicken mit dem Kopf.
    *   **Augen schlieÃŸen:** Kurzes, vollstÃ¤ndiges SchlieÃŸen beider Augen.
*   **Standardaktion:** Die Standardaktion ist ein Doppelklick. Das System sollte jedoch erweiterbar sein, um andere Aktionen (z.B. Rechtsklick, Einzelklick, Scrollen) durch verschiedene Trigger oder Trigger-Kombinationen zu ermÃ¶glichen.

## 3. Technische Umsetzung

### 3.1 Verwendete Technologien (VorschlÃ¤ge)

*   **Programmiersprache:** Python 3.8+ (breite VerfÃ¼gbarkeit von ML- und CV-Bibliotheken)
*   **Computer Vision Stack:**
    *   **OpenCV** - Kamerazugriff und Bildverarbeitung
    *   **MediaPipe** - Hochperformante Gesichts- und Landmark-Detektion (468 Punkte)
    *   **NumPy** - Numerische Operationen und Datenverarbeitung
*   **Systemsteuerung:**
    *   **PyAutoGUI** - Maus-/Tastaturereignisse
    *   **Windows API (ctypes)** - Native Cursor-Kontrolle und visuelle RÃ¼ckmeldung
*   **Konfiguration:** YAML-basierte Einstellungen mit JSON-Kalibrierungsdaten

### 3.2 Kalibrierung

*   **Notwendigkeit:** Eine prÃ¤zise individuelle Kalibrierung ist entscheidend fÃ¼r die Genauigkeit des Eyetrackers.
*   **Kalibrierungsprogramm:** Es wird eine separate ausfÃ¼hrbare Datei oder ein Skript (`calibration.exe` oder `calibrate.py`) bereitgestellt, das die Kalibrierungsdaten fÃ¼r das Hauptprogramm erzeugt und speichert.
*   **Initialisierung:** Beim ersten Start des Hauptprogramms prÃ¼ft dieses, ob gÃ¼ltige Kalibrierungsdaten vorliegen.
    *   **Keine Daten:** Wenn keine Daten gefunden werden, wird der Benutzer entsprechend informiert (z.B. durch eine Meldung) und das Kalibrierungsprogramm wird automatisch gestartet.
    *   **Daten vorhanden:** Sind Daten vorhanden, wird das Hauptprogramm normal gestartet.
*   **Aktualisierung:** Die Kalibrierung sollte jederzeit Ã¼ber das dedizierte Kalibrierungsprogramm aktualisierbar sein.
*   **Kalibrierungsprozess:** Der Benutzer wird aufgefordert, verschiedene Punkte auf dem Bildschirm zu fixieren (z.B. ein 3x3-Raster), wÃ¤hrend die Blickrichtung erfasst wird, um eine individuelle Blickrichtungsmatrix oder ein Modell zu erstellen.

### 3.3 Architekturelle Ãœberlegungen

*   **Modulare Struktur:** Das Projekt sollte modular aufgebaut sein, um eine einfache Erweiterung und Wartung zu ermÃ¶glichen (z.B. separate Module fÃ¼r Kamerazugriff, Gesichtserkennung, BlickrichtungsschÃ¤tzung, Maussteuerung, Triggererkennung).
*   **Performance:** Besondere Aufmerksamkeit muss der Echtzeitverarbeitung und der Ressourcenschonung gewidmet werden, um eine flÃ¼ssige Benutzererfahrung zu gewÃ¤hrleisten, auch auf weniger leistungsstarken Notebooks.
*   **Konfigurationsdateien:** Einstellbare Parameter (Timer fÃ¼r InaktivitÃ¤t, Korrekturzeitraum, Triggerschwellenwerte) sollten in einer Konfigurationsdatei gespeichert werden, um eine einfache Anpassung durch den Benutzer zu ermÃ¶glichen.

## 4. Akzeptanzkriterien

*   Der Mauszeiger kann prÃ¤zise und reaktionsschnell durch Augenbewegungen gesteuert werden.
*   Trigger (z.B. Kopfnicken, Augen schlieÃŸen) werden zuverlÃ¤ssig erkannt und lÃ¶sen die korrekten Aktionen aus.
*   Das Programm startet und beendet sich wie spezifiziert.
*   Die Kalibrierung ist einfach durchzufÃ¼hren und speichert zuverlÃ¤ssig Benutzerdaten.
*   Die visuelle RÃ¼ckmeldung des Mauszeigers ist klar und hilfreich.
*   Das System ist stabil und verursacht keine Ã¼bermÃ¤ÃŸige CPU-/Batterielast bei normaler Nutzung.

## 5. Aktuelle Implementierung

### âœ… Implementierte Features (v1.0 Prototyp):
- **Basis-Kopfsteuerung** - FunktionsfÃ¤hige Maussteuerung durch Kopfbewegungen
- **MediaPipe Integration** - Robuste Gesichtserkennung mit 468 Landmarks
- **Echtzeit-Performance** - Optimiert fÃ¼r 30+ FPS auf Standard-Hardware
- **Debug-Visualisierung** - Live-Feedback der Gesichtserkennung
- **Modulare Architektur** - Austauschbare Komponenten fÃ¼r einfache Erweiterung

### ğŸ”„ In Entwicklung (v2.0):
- **3x3-Kalibrierungssystem** - PrÃ¤zise individuelle Gaze-Estimation
- **Trigger-Erkennung** - Blinzeln und Kopfnicken fÃ¼r Aktionen
- **Erweiterte Maussteuerung** - Ruheposition, Auto-Return, vergrÃ¶ÃŸerter Cursor
- **Konfigurationssystem** - YAML-basierte Einstellungen

### ğŸš€ Geplante Features (v3.0+):
- Echte Augenbewegungssteuerung (Eye-Tracking)
- Mehrere Aktionstypen (Rechts-/Linksklick, Scrollen)
- Multi-Monitor-UnterstÃ¼tzung
- GUI fÃ¼r Einstellungen
- Erweiterte Trigger-Kombinationen

---

## 6. Installation & Setup

### Voraussetzungen:
- Python 3.8 oder hÃ¶her
- Webcam (integriert oder USB)
- Windows 10/11 (primÃ¤r getestet)

### Installation:
```bash
# 1. Repository klonen
git clone https://github.com/yourusername/EyetrackerRemoteMouseController.git
cd EyetrackerRemoteMouseController

# 2. Virtual Environment erstellen
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# 3. Dependencies installieren
pip install -r requirements.txt

# 4. Basis-Prototyp testen
python main.py
```

### Troubleshooting:
- **Kamera nicht gefunden:** PrÃ¼fen Sie `config.yaml` â†’ `camera.device_id`
- **Performance-Probleme:** Reduzieren Sie AuflÃ¶sung in `config.yaml`
- **Windows Cursor-Probleme:** Programm als Administrator ausfÃ¼hren

---

## 7. GitHub Repository Setup

### Repository erstellen:
1. Auf GitHub neues Repository erstellen: `EyetrackerRemoteMouseController`
2. Local repository mit GitHub verbinden:

```bash
# Remote hinzufÃ¼gen
git remote add origin https://github.com/yourusername/EyetrackerRemoteMouseController.git

# Ersten Push durchfÃ¼hren
git branch -M main
git push -u origin main
```

### FÃ¼r Entwickler:
```bash
# Repository klonen und Setup
git clone https://github.com/yourusername/EyetrackerRemoteMouseController.git
cd EyetrackerRemoteMouseController

# Virtual Environment und Dependencies
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt

# Development mit Debug-Logs
python main.py --log-level DEBUG
```

---

## 8. Projektstruktur

```
EyetrackerRemoteMouseController/
â”œâ”€â”€ main.py                 # ğŸš€ Hauptanwendung (Prototyp)
â”œâ”€â”€ eye_tracker.py          # ğŸ‘ï¸ MediaPipe-basierte Gesichtserkennung
â”œâ”€â”€ mouse_controller.py     # ğŸ–±ï¸ Windows-optimierte Maussteuerung
â”œâ”€â”€ trigger_detector.py     # âš¡ Blinzel-/Kopfnicken-Erkennung
â”œâ”€â”€ calibration.py          # ğŸ“ 3x3-Kalibrierungssystem
â”œâ”€â”€ config.py              # âš™ï¸ YAML-Konfigurationsverwaltung
â”œâ”€â”€ utils.py               # ğŸ› ï¸ Performance-Monitoring & Utilities
â”œâ”€â”€ requirements.txt       # ğŸ“¦ Python-Dependencies
â”œâ”€â”€ .gitignore            # ğŸš« Git-Ignore-Regeln
â”œâ”€â”€ CLAUDE.md             # ğŸ“– Technische Dokumentation
â””â”€â”€ README.md             # ğŸ“‹ Diese Datei
```

---

## 9. ZukÃ¼nftige Erweiterungen

*   **PrÃ¤zisions-Verbesserungen:** Machine Learning fÃ¼r adaptive Kalibrierung
*   **Erweiterte Trigger:** Anpassbare Gesten fÃ¼r verschiedene Aktionen
*   **Cross-Platform:** Linux/macOS UnterstÃ¼tzung
*   **Accessibility Integration:** Windows Accessibility API
*   **Performance-Optimierung:** GPU-Acceleration fÃ¼r CV-Pipeline
*   **User Interface:** Electron-basierte Setup-/Konfigurations-GUI
