# Eyetracker Remote Mouse Controller f√ºr Notebooks

üéØ **Status: Funktionsf√§higer Prototyp verf√ºgbar!** 

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8+-green.svg)](https://opencv.org/)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10+-red.svg)](https://mediapipe.dev/)

## Schnellstart

### Sofort testen (Basis-Prototyp):
```bash
# Repository klonen
git clone <REPO_URL>
cd EyetrackerRemoteMouseController

# Virtual Environment aktivieren und Dependencies installieren
.venv\Scripts\activate
pip install -r requirements.txt

# Basis-Prototyp starten (Kopfsteuerung)
python main.py
```

**Steuerung:** Bewegen Sie Ihren Kopf um die Maus zu steuern. Dr√ºcken Sie 'q' zum Beenden, 'c' zum Zentrieren.

---

## 1. Projekt√ºbersicht

Dieses Projekt zielt darauf ab, einen innovativen und ressourcenschonenden Eyetracker-RemoteMouse-Controller f√ºr Notebooks zu entwickeln. Das System erm√∂glicht die Steuerung des Mauszeigers und die Ausf√ºhrung von Mausklicks ausschlie√ülich durch Augen- und Kopfbewegungen, unter Verwendung der integrierten Webcam des Notebooks. Das ultimative Ziel ist es, die Abh√§ngigkeit von physischen M√§usen oder Touchpads zu reduzieren oder ganz zu eliminieren und so eine intuitive, erm√ºdungsfreie Interaktion zu erm√∂glichen.

## 2. Kernfunktionen und Anforderungen

### 2.1 Start und Beenden des Programms

*   **Programmstart:** Das Hauptprogramm wird durch einen Doppelklick mit der rechten Maustaste (oder Touchpad-Taste) ausgel√∂st, unabh√§ngig von der aktuellen Position des Mauszeigers.
*   **Automatisches Beenden:** Wenn der Mauszeiger eine einstellbare Zeit (Standard: 5-10 Sekunden) in seiner Ruheposition verweilt, ohne dass eine erkennbare Augenbewegung zur Mauszeigerverschiebung erfolgt, beendet sich das Programm automatisch. Es muss dann wie oben beschrieben neu gestartet werden.

### 2.2 Mauszeiger-Status und Visualisierung

*   **Ruheposition:** Nach dem Start des Programms oder nach jeder durchgef√ºhrten Aktion befindet sich der Mauszeiger in seiner vertikal und horizontal zentrierten Ruheposition in der Bildschirmmitte.
*   **Visuelle R√ºckmeldung:** In der Ruheposition ist der Mauszeiger deutlich sichtbar gr√∂√üer, um den aktiven Status des Eyetrackers zu signalisieren.
*   **R√ºckkehr in die Ruheposition:**
    *   Nach jeder erfolgreich ausgef√ºhrten Aktion (Mauszeiger verschoben und Trigger erkannt) kehrt der Mauszeiger sofort in seine Ruheposition zur√ºck.
    *   Wenn l√§nger als eine einstellbare Zeit (Standard: 1 Sekunde) kein Blick- oder Kopfbewegungsbefehl erfolgt, kehrt der Mauszeiger ebenfalls in seine Ruheposition zur√ºck.

### 2.3 Mauszeiger-Steuerung durch Augenbewegung

*   **Bewegung aus der Ruheposition:** Wenn der Benutzer den zentrierten Mauszeiger mit den Augen fixiert und eine **ann√§hernd lineare Augenbewegung** von der Bildschirmmitte weg ausf√ºhrt, folgt der Mauszeiger dieser Bewegung. Kreiselnde, zick-zack- oder wellenf√∂rmige Augenbewegungen aus der Ruheposition heraus werden ignoriert, um unbeabsichtigte Bewegungen zu vermeiden.
*   **Fixierung und Halten:** Der Mauszeiger bleibt an der Stelle stehen, an die er verschoben wurde und wo der Benutzer ihn **l√§nger als eine Sekunde ununterbrochen** (ohne Blinzeln) fixiert hat.
*   **Feinjustierung:** Nach der Erkennung einer ann√§hernd linearen Bewegung und dem Erreichen der Zielregion ist f√ºr eine kurze, einstellbare Zeitspanne (Standard: 0.5 Sekunden) eine Feinjustierung des Mauszeigers durch subtile Augenbewegungen m√∂glich, bevor die Position endg√ºltig fixiert wird.

### 2.4 Aktionen und Trigger

*   **Aktionsausf√ºhrung:** Sobald der Mauszeiger an einer gew√ºnschten Position fixiert wurde, kann durch einen spezifischen Trigger eine Aktion ausgef√ºhrt werden.
*   **Beispiele f√ºr Trigger (erweiterbar):**
    *   **Kopfnicken:** Ein kurzes, klares Nicken mit dem Kopf.
    *   **Augen schlie√üen:** Kurzes, vollst√§ndiges Schlie√üen beider Augen.
*   **Standardaktion:** Die Standardaktion ist ein Doppelklick. Das System sollte jedoch erweiterbar sein, um andere Aktionen (z.B. Rechtsklick, Einzelklick, Scrollen) durch verschiedene Trigger oder Trigger-Kombinationen zu erm√∂glichen.

## 3. Technische Umsetzung

### 3.1 Verwendete Technologien (Vorschl√§ge)

*   **Programmiersprache:** Python 3.8+ (breite Verf√ºgbarkeit von ML- und CV-Bibliotheken)
*   **Computer Vision Stack:**
    *   **OpenCV** - Kamerazugriff und Bildverarbeitung
    *   **MediaPipe** - Hochperformante Gesichts- und Landmark-Detektion (468 Punkte)
    *   **NumPy** - Numerische Operationen und Datenverarbeitung
*   **Systemsteuerung:**
    *   **PyAutoGUI** - Maus-/Tastaturereignisse
    *   **Windows API (ctypes)** - Native Cursor-Kontrolle und visuelle R√ºckmeldung
*   **Konfiguration:** YAML-basierte Einstellungen mit JSON-Kalibrierungsdaten

### 3.2 Kalibrierung

*   **Notwendigkeit:** Eine pr√§zise individuelle Kalibrierung ist entscheidend f√ºr die Genauigkeit des Eyetrackers.
*   **Kalibrierungsprogramm:** Es wird eine separate ausf√ºhrbare Datei oder ein Skript (`calibration.exe` oder `calibrate.py`) bereitgestellt, das die Kalibrierungsdaten f√ºr das Hauptprogramm erzeugt und speichert.
*   **Initialisierung:** Beim ersten Start des Hauptprogramms pr√ºft dieses, ob g√ºltige Kalibrierungsdaten vorliegen.
    *   **Keine Daten:** Wenn keine Daten gefunden werden, wird der Benutzer entsprechend informiert (z.B. durch eine Meldung) und das Kalibrierungsprogramm wird automatisch gestartet.
    *   **Daten vorhanden:** Sind Daten vorhanden, wird das Hauptprogramm normal gestartet.
*   **Aktualisierung:** Die Kalibrierung sollte jederzeit √ºber das dedizierte Kalibrierungsprogramm aktualisierbar sein.
*   **Kalibrierungsprozess:** Der Benutzer wird aufgefordert, verschiedene Punkte auf dem Bildschirm zu fixieren (z.B. ein 3x3-Raster), w√§hrend die Blickrichtung erfasst wird, um eine individuelle Blickrichtungsmatrix oder ein Modell zu erstellen.

### 3.3 Architekturelle √úberlegungen

*   **Modulare Struktur:** Das Projekt sollte modular aufgebaut sein, um eine einfache Erweiterung und Wartung zu erm√∂glichen (z.B. separate Module f√ºr Kamerazugriff, Gesichtserkennung, Blickrichtungssch√§tzung, Maussteuerung, Triggererkennung).
*   **Performance:** Besondere Aufmerksamkeit muss der Echtzeitverarbeitung und der Ressourcenschonung gewidmet werden, um eine fl√ºssige Benutzererfahrung zu gew√§hrleisten, auch auf weniger leistungsstarken Notebooks.
*   **Konfigurationsdateien:** Einstellbare Parameter (Timer f√ºr Inaktivit√§t, Korrekturzeitraum, Triggerschwellenwerte) sollten in einer Konfigurationsdatei gespeichert werden, um eine einfache Anpassung durch den Benutzer zu erm√∂glichen.

## 4. Akzeptanzkriterien

*   Der Mauszeiger kann pr√§zise und reaktionsschnell durch Augenbewegungen gesteuert werden.
*   Trigger (z.B. Kopfnicken, Augen schlie√üen) werden zuverl√§ssig erkannt und l√∂sen die korrekten Aktionen aus.
*   Das Programm startet und beendet sich wie spezifiziert.
*   Die Kalibrierung ist einfach durchzuf√ºhren und speichert zuverl√§ssig Benutzerdaten.
*   Die visuelle R√ºckmeldung des Mauszeigers ist klar und hilfreich.
*   Das System ist stabil und verursacht keine √ºberm√§√üige CPU-/Batterielast bei normaler Nutzung.

## 5. Aktuelle Implementierung

### ‚úÖ Implementierte Features (v1.0 Prototyp):
- **Basis-Kopfsteuerung** - Funktionsf√§hige Maussteuerung durch Kopfbewegungen
- **MediaPipe Integration** - Robuste Gesichtserkennung mit 468 Landmarks
- **Echtzeit-Performance** - Optimiert f√ºr 30+ FPS auf Standard-Hardware
- **Debug-Visualisierung** - Live-Feedback der Gesichtserkennung
- **Modulare Architektur** - Austauschbare Komponenten f√ºr einfache Erweiterung

### üîÑ In Entwicklung (v2.0):
- **3x3-Kalibrierungssystem** - Pr√§zise individuelle Gaze-Estimation
- **Trigger-Erkennung** - Blinzeln und Kopfnicken f√ºr Aktionen
- **Erweiterte Maussteuerung** - Ruheposition, Auto-Return, vergr√∂√üerter Cursor
- **Konfigurationssystem** - YAML-basierte Einstellungen

### üöÄ Geplante Features (v3.0+):
- Echte Augenbewegungssteuerung (Eye-Tracking)
- Mehrere Aktionstypen (Rechts-/Linksklick, Scrollen)
- Multi-Monitor-Unterst√ºtzung
- GUI f√ºr Einstellungen
- Erweiterte Trigger-Kombinationen

---

## 6. Installation & Setup

### Voraussetzungen:
- Python 3.8 oder h√∂her
- Webcam (integriert oder USB)
- Windows 10/11 (prim√§r getestet)

### Installation:
```bash
# 1. Repository klonen
git clone https://github.com/yourusername/EyetrackerRemoteMouseController.git
cd EyetrackerRemoteMouseController

# 2. Virtual Environment erstellen
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# 3. Dependencies installieren
pip install -r requirements.txt

# 4. Basis-Prototyp testen
python main.py
```

### Troubleshooting:
- **Kamera nicht gefunden:** Pr√ºfen Sie `config.yaml` ‚Üí `camera.device_id`
- **Performance-Probleme:** Reduzieren Sie Aufl√∂sung in `config.yaml`
- **Windows Cursor-Probleme:** Programm als Administrator ausf√ºhren

---

## 7. GitHub Repository Setup

### Repository erstellen:
1. Auf GitHub neues Repository erstellen: `EyetrackerRemoteMouseController`
2. Local repository mit GitHub verbinden:

```bash
# Remote hinzuf√ºgen
git remote add origin https://github.com/yourusername/EyetrackerRemoteMouseController.git

# Ersten Push durchf√ºhren
git branch -M main
git push -u origin main
```

### F√ºr Entwickler:
```bash
# Repository klonen und Setup
git clone https://github.com/yourusername/EyetrackerRemoteMouseController.git
cd EyetrackerRemoteMouseController

# Virtual Environment und Dependencies
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt

# Development mit Debug-Logs
python main.py --log-level DEBUG
```

---

## 8. Projektstruktur

```
EyetrackerRemoteMouseController/
‚îú‚îÄ‚îÄ main.py                 # üöÄ Hauptanwendung (Prototyp)
‚îú‚îÄ‚îÄ eye_tracker.py          # üëÅÔ∏è MediaPipe-basierte Gesichtserkennung
‚îú‚îÄ‚îÄ mouse_controller.py     # üñ±Ô∏è Windows-optimierte Maussteuerung
‚îú‚îÄ‚îÄ trigger_detector.py     # ‚ö° Blinzel-/Kopfnicken-Erkennung
‚îú‚îÄ‚îÄ calibration.py          # üìê 3x3-Kalibrierungssystem
‚îú‚îÄ‚îÄ config.py              # ‚öôÔ∏è YAML-Konfigurationsverwaltung
‚îú‚îÄ‚îÄ utils.py               # üõ†Ô∏è Performance-Monitoring & Utilities
‚îú‚îÄ‚îÄ requirements.txt       # üì¶ Python-Dependencies
‚îú‚îÄ‚îÄ .gitignore            # üö´ Git-Ignore-Regeln
‚îú‚îÄ‚îÄ CLAUDE.md             # üìñ Technische Dokumentation
‚îî‚îÄ‚îÄ README.md             # üìã Diese Datei
```

---

## 9. Zuk√ºnftige Erweiterungen

*   **Pr√§zisions-Verbesserungen:** Machine Learning f√ºr adaptive Kalibrierung
*   **Erweiterte Trigger:** Anpassbare Gesten f√ºr verschiedene Aktionen
*   **Cross-Platform:** Linux/macOS Unterst√ºtzung
*   **Accessibility Integration:** Windows Accessibility API
*   **Performance-Optimierung:** GPU-Acceleration f√ºr CV-Pipeline
*   **User Interface:** Electron-basierte Setup-/Konfigurations-GUI
