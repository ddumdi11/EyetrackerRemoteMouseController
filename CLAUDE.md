# Eyetracker-RemoteMouse-Controller - Claude Development Guide

## Projekt√ºbersicht
Innovativer Eyetracker-RemoteMouse-Controller f√ºr Notebooks, der ausschlie√ülich die integrierte Webcam nutzt.
Erm√∂glicht Maussteuerung durch Augen- und Kopfbewegungen ohne physische Maus/Touchpad.
**üéØ Ziel:** Intuitive, erm√ºdungsfreie Computer-Interaktion durch Blicksteuerung.

## Technische Anforderungen
- Python 3.8+ mit Computer Vision Bibliotheken
- OpenCV f√ºr Webcam-Zugriff und Bildverarbeitung
- Dlib f√ºr Gesichts- und Landmark-Detektion
- PyAutoGUI f√ºr Maus-/Tastatursteuerung
- Windows 11 kompatibel (prim√§res Zielssystem)

## Projektstruktur
```
EyetrackerRemoteMouseController/
‚îú‚îÄ‚îÄ main.py                  # Haupt-Eyetracker-Anwendung
‚îú‚îÄ‚îÄ calibration.py          # Kalibrierungsprogramm
‚îú‚îÄ‚îÄ eye_tracker.py          # Eye-Tracking-Engine (OpenCV + Dlib)
‚îú‚îÄ‚îÄ mouse_controller.py     # Maussteuerung und Cursor-Verwaltung
‚îú‚îÄ‚îÄ trigger_detector.py     # Trigger-Erkennung (Kopfnicken, Blinzeln)
‚îú‚îÄ‚îÄ config.py              # Konfiguration und Einstellungen
‚îú‚îÄ‚îÄ utils.py               # Hilfsfunktionen
‚îú‚îÄ‚îÄ requirements.txt       # Abh√§ngigkeiten
‚îú‚îÄ‚îÄ README.md             # Benutzeranleitung
‚îî‚îÄ‚îÄ CLAUDE.md            # Diese Datei
```

## Entwicklungsrichtlinien
- **Performance-First**: Echtzeitverarbeitung bei niedriger CPU-Last
- **Windows-First**: Native Windows API Integration √ºber ctypes
- **Robustheit**: Graceful Degradation bei schlechten Lichtverh√§ltnissen
- **Modulares Design**: Austauschbare Komponenten f√ºr verschiedene Tracking-Algorithmen
- **Type Hints**: F√ºr bessere Code-Qualit√§t und Entwicklerfreundlichkeit
- **Logging**: Ausf√ºhrliche Telemetrie f√ºr Debugging und Performance-Optimierung

## Core Features
1. **Program Lifecycle**: Rechts-Doppelklick Start ‚Üí Auto-Stop nach Inaktivit√§t
2. **Rest Position**: Zentrierte Cursor-Ruheposition mit visueller Vergr√∂√üerung
3. **Linear Eye Movement**: Erkennung bewusster linearer Augenbewegungen (keine Zick-Zack-Muster)
4. **Gaze Fixation**: Mindestens 1 Sekunde Fixierung f√ºr Positionsbest√§tigung
5. **Fine Adjustment**: 0.5s Feinjustierungs-Zeitfenster nach initialer Positionierung
6. **Trigger Detection**: Kopfnicken und Augenschlie√üen f√ºr Aktionsausl√∂sung
7. **Action Execution**: Standard-Doppelklick mit Erweiterbarkeit f√ºr weitere Aktionen
8. **Individual Calibration**: 3x3-Raster-Kalibrierung f√ºr pr√§zise Blickrichtungssch√§tzung
9. **Visual Feedback**: Vergr√∂√üerter Cursor in Ruheposition als Aktivit√§tsindikator

## Computer Vision Pipeline
**Webcam-Zugriff:**
- OpenCV `cv2.VideoCapture(0)` f√ºr Kamera-Interface
- Optimale Aufl√∂sung: 640x480 oder 1280x720 je nach Hardware
- 30 FPS Ziel-Framerate f√ºr fl√ºssige Reaktionen

**Gesichts- und Landmark-Detektion:**
- Dlib's `get_frontal_face_detector()` f√ºr Gesichtserkennung
- 68-Punkt Facial Landmark Modell f√ºr Augenpositionen
- Robuste Tracking-Algorithmen f√ºr Kopfbewegungen

**Blickrichtungssch√§tzung:**
- Pupillen-Zentrum-Extraktion aus Augen-ROI
- Kalibrierungsmatrix f√ºr Screen-zu-Gaze-Mapping
- Gleitender Durchschnitt zur Rauschunterdr√ºckung
- Linear Movement Detection √ºber Bewegungsvektor-Analyse

## Testing Approach
- **Hardware-Tests**: Verschiedene Webcam-Qualit√§ten und Beleuchtungsbedingungen
- **Pr√§zisions-Tests**: Kalibrierungs-Genauigkeit √ºber verschiedene Nutzerprofile
- **Performance-Tests**: CPU-Last und Reaktionszeit-Messungen
- **Robustheit**: Verhalten bei Gesichts-Verlust oder extremen Kopfbewegungen
- **Usability**: Erm√ºdungstests und Lernkurven-Analyse

## Deployment
- Standalone Python-Script f√ºr Entwicklung
- PyInstaller f√ºr .exe-Distribution mit allen Dependencies
- Installer mit automatischer Kalibrierungsroutine

## üéØ Aktueller Status - Projektbeginn
- **Konzeptphase**: ‚úÖ README.md und technische Spezifikation vollst√§ndig
- **CLAUDE.md**: ‚úÖ Aktualisiert f√ºr Eyetracker-Projekt
- **Architektur**: ‚è≥ Modulares Design geplant
- **Dependencies**: ‚è≥ OpenCV + Dlib + PyAutoGUI Stack
- **Prototyp**: ‚è≥ Noch nicht implementiert

## üìã Development Roadmap
**Phase 1 - Grundlagen (Proof of Concept)**
- ‚è≥ Webcam-Zugriff und Gesichtserkennung
- ‚è≥ Einfache Augenpunkt-Detektion
- ‚è≥ Basis-Maussteuerung ohne Kalibrierung
- ‚è≥ Primitive Trigger-Erkennung (Blinzeln)

**Phase 2 - Kalibrierung und Pr√§zision**
- ‚è≥ 3x3-Raster-Kalibrierungssystem
- ‚è≥ Blickrichtungs-Mapping-Algorithmus
- ‚è≥ Lineare Bewegungserkennung
- ‚è≥ Feinjustierungs-Mechanismus

**Phase 3 - Produktionsreife**
- ‚è≥ Robuste Start/Stop-Mechanismen
- ‚è≥ Cursor-Visualisierung und Feedback
- ‚è≥ Konfigurierbare Timer und Schwellenwerte
- ‚è≥ Windows API Integration f√ºr Cursor-Kontrolle

**Phase 4 - Erweiterte Features**
- ‚è≥ Mehrere Trigger-Typen (Kopfnicken, Augenbewegungen)
- ‚è≥ Verschiedene Aktionstypen (Rechts-/Linksklick, Scrollen)
- ‚è≥ Multi-Monitor-Unterst√ºtzung
- ‚è≥ Benutzeroberfl√§che f√ºr Einstellungen

## Installation (Core Dependencies)
```bash
pip install opencv-python dlib pyautogui numpy
# Zus√§tzlich: dlib shape predictor model herunterladen
```

## üéØ Kritische Erfolgsfaktoren
- **Kalibrierung**: Individuelle Anpassung ist absolut entscheidend
- **Performance**: <100ms Latenz f√ºr nat√ºrliche Interaktion
- **Robustheit**: Graceful Degradation bei Hardware-Problemen
- **Ergonomie**: Erm√ºdungsfreie Nutzung √ºber l√§ngere Zeitr√§ume

## üîÑ Benutzer-Workflow 
1. **Kalibrierung** ‚Üí Einmalig 3x3-Raster-Setup durchf√ºhren
2. **Programmstart** ‚Üí Rechts-Doppelklick aktiviert Eyetracker
3. **Blicksteuerung** ‚Üí Lineare Augenbewegung von Bildschirmmitte
4. **Positionierung** ‚Üí 1s Fixierung + 0.5s Feinjustierung
5. **Aktion** ‚Üí Kopfnicken/Blinzeln f√ºr Doppelklick
6. **Auto-Ende** ‚Üí Nach 5-10s Inaktivit√§t automatischer Stop

## üõ†Ô∏è Kernkomponenten-Architektur

### Eye Tracker Engine
```python
class EyeTracker:
    def __init__(self):
        self.face_detector = dlib.get_frontal_face_detector()
        self.landmark_predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
        
    def get_gaze_point(self, frame):
        # 1. Gesicht detektieren
        # 2. 68 Landmarks extrahieren
        # 3. Augen-ROI bestimmen
        # 4. Pupillen-Zentrum berechnen
        # 5. Kalibrierungsmatrix anwenden
        return screen_x, screen_y
```

### Mouse Controller
```python
class MouseController:
    def __init__(self):
        self.rest_position = (screen_width // 2, screen_height // 2)
        self.is_active = False
        
    def set_enlarged_cursor(self):
        # Windows API f√ºr vergr√∂√üerten Cursor
        
    def smooth_move_to(self, target_x, target_y):
        # Sanfte Bewegung zur Zielposition
        
    def return_to_rest(self):
        # R√ºckkehr zur Bildschirmmitte
```

### Linear Movement Detector
```python
class LinearMovementDetector:
    def is_linear_movement(self, gaze_points, threshold=0.15):
        # Analysiert Bewegungsvektor auf Linearit√§t
        # Filtert Zick-Zack und kreiselnde Bewegungen
        # Retourniert True f√ºr bewusste Bewegungen
```

## üö¶ Technische Herausforderungen & L√∂sungsans√§tze

**Herausforderung 1: Beleuchtungsabh√§ngigkeit**
- *L√∂sung*: Adaptive Schwellenwerte + Infrarot-Unterst√ºtzung falls verf√ºgbar

**Herausforderung 2: Individuelle Kalibrierung**
- *L√∂sung*: Machine Learning f√ºr adaptive Verbesserung √ºber Zeit

**Herausforderung 3: Performance vs. Genauigkeit**
- *L√∂sung*: Multi-Threading + optimierte OpenCV-Pipeline

**Herausforderung 4: Falsch-Positive bei Triggern**
- *L√∂sung*: Kombinierte Trigger + Confidence-Scoring